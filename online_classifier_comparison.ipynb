{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online classifier comparison\n",
    "\n",
    "This notebook takes a single epoch from either the MOABB or the pediatric dataset and computes the classification running a preset number of voters. The execution time is measured.\n",
    "The end part of the notebook can do the plot of the accuracy vs number voters.\n",
    "\n",
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "c:\\Users\\danie\\miniconda3\\envs\\ssvep-validation\\Lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    }
   ],
   "source": [
    "# Default libraries\n",
    "import re\n",
    "import mne\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from moabb.datasets import Wang2016, SSVEPExo\n",
    "from moabb.paradigms import FilterBankSSVEP, SSVEP\n",
    "from moabb.pipelines import ExtendedSSVEPSignal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "\n",
    "import time\n",
    "from cupyx.profiler import benchmark\n",
    "\n",
    "# Import custom libraries\n",
    "from functions import data_tools\n",
    "from functions import processing\n",
    "from functions import classification\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorCCA as CCA\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorMSI as MSI\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorMEC as MEC\n",
    "\n",
    "# Magic command to reload libraries\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear distribution of voters\n",
    "n_voters = np.linspace(1, 100, 5, dtype=int)\n",
    "n_epochs = 2   # Number of epochs to be used in the classification\n",
    "\n",
    "\n",
    "test_dataset = \"Wang2016\"    # \"Wang2016\" or \"BCI4Kids\"\n",
    "dataset_nsubjects = {\n",
    "    \"Wang2016\": 34,\n",
    "    \"BCI4Kids\": 6\n",
    "}\n",
    "# Generate random indexes\n",
    "random_seed = 42\n",
    "# random.seed(random_seed)\n",
    "# subject = random.randint(0, dataset_nsubjects[dataset] - 1, random_seed)\n",
    "\n",
    "\n",
    "# Classifier settings \n",
    "harmonic_count = 2\n",
    "\n",
    "# Create dataframes for each classifier\n",
    "columns = {\n",
    "    'n_voters': n_voters,\n",
    "    'CPU_time': np.nan,\n",
    "    'CPU_accuracy': np.nan,\n",
    "    'GPU_time': np.nan,\n",
    "    'GPU_accuracy': np.nan\n",
    "    }\n",
    "cca_df = pd.DataFrame(columns)\n",
    "# msi_df = pd.DataFrame(index=n_voters, columns=['CPU_time', 'CPU_prediction', 'GPU_time', 'GPU_prediction'])\n",
    "# mec_df = pd.DataFrame(index=n_voters, columns=['CPU_time', 'CPU_prediction', 'GPU_time', 'GPU_prediction'])\n",
    "# rg_logreg_df = pd.DataFrame(index=n_voters, columns=['CPU_time', 'CPU_prediction', 'GPU_time', 'GPU_prediction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Get a randomized single epoch from a single trial in the selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n"
     ]
    }
   ],
   "source": [
    "if (test_dataset == \"Wang2016\"):\n",
    "    # Get trial data\n",
    "    dataset = Wang2016()\n",
    "    subject_data = dataset.get_data(subjects=[1])\n",
    "    time_trim = [0.5, 5.5] # Times to trim the data [sec]\n",
    "    stimulus_freqs = [float(freq) for freq in dataset.event_id.keys()]  # Stimulus frequencies [Hz]\n",
    "    srate = subject_data[1][\"0\"][\"0\"].info['sfreq'] # Sampling rate [Hz]\n",
    "\n",
    "    # Frequency bands\n",
    "    first_column = np.arange(1, 11) * 8\n",
    "    second_column = np.full(10, 88)\n",
    "    cca_subbands = np.column_stack((first_column, second_column))\n",
    "\n",
    "    # Get epoched data\n",
    "    # - Preallocate data\n",
    "    epochs_list = [None] * len(subject_data)\n",
    "    events_list = [None] * len(subject_data)\n",
    "\n",
    "    # - Obtain epochs and events\n",
    "    for s, subject in subject_data.items():\n",
    "        [events_list[s-1], epochs_list[s-1]] = data_tools.moabb_events_to_np(\n",
    "            mne_raw = subject[\"0\"][\"0\"],\n",
    "            tmin = time_trim[0],\n",
    "            tmax = time_trim[1],\n",
    "            events_dict = dataset.event_id,\n",
    "            )\n",
    "        \n",
    "    # - Convert lists to np.ndarrays\n",
    "    eeg_channels = subject_data[1][\"0\"][\"0\"].ch_names\n",
    "    epochs_np = np.float32(np.array(epochs_list))\n",
    "    events_np = np.array(events_list[0][:,2]) - 1   # The `-1` is to make the labels start at 0\n",
    "\n",
    "    # - Remove stim channel and pick subset of epochs\n",
    "    eeg_channels = eeg_channels[:-1]\n",
    "    epochs_np = epochs_np[:, :, :-1, :]\n",
    "    n_samples = epochs_np.shape[-1]\n",
    "\n",
    "    # - Get randomized subset of epochs\n",
    "    total_n_epochs = epochs_np.shape[1]\n",
    "    epochs_subset = random.sample(range(total_n_epochs), n_epochs)\n",
    "    # epochs_subset = 0\n",
    "    epochs = np.float32(epochs_np[:,epochs_subset,:,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cca = CCA()\n",
    "cca_voters = 1\n",
    "cca_gpu = False\n",
    "\n",
    "def setup_cca():\n",
    "    cca.setup_feature_extractor(\n",
    "        harmonics_count = harmonic_count,\n",
    "        targets_frequencies = stimulus_freqs,\n",
    "        sampling_frequency = srate,\n",
    "        samples_count = n_samples,\n",
    "        filter_order = 12,\n",
    "        subbands = cca_subbands,\n",
    "        voters_count = cca_voters,\n",
    "        use_gpu = cca_gpu,\n",
    "        random_seed = random_seed\n",
    "        )\n",
    "    \n",
    "mec = MEC()\n",
    "def setup_mec(voters, use_gpu):\n",
    "    # Missing implementation\n",
    "    pass\n",
    "\n",
    "msi = MSI()\n",
    "def setup_msi(voters, use_gpu):\n",
    "    # Missing implementation\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU classification\n",
    "\n",
    "### CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCA CPU processing\n",
      "- voters: 1\n",
      "Elapsed time: 0.29512643814086914\n",
      "- voters: 1\n",
      "Elapsed time: 0.2578895092010498\n",
      "- voters: 25\n",
      "Elapsed time: 0.9921317100524902\n",
      "- voters: 25\n",
      "Elapsed time: 1.0233123302459717\n",
      "- voters: 50\n",
      "Elapsed time: 1.9098901748657227\n",
      "- voters: 50\n",
      "Elapsed time: 1.9370973110198975\n",
      "- voters: 75\n",
      "Elapsed time: 2.849289655685425\n",
      "- voters: 75\n",
      "Elapsed time: 2.8345789909362793\n",
      "- voters: 100\n",
      "Elapsed time: 3.717536211013794\n",
      "- voters: 100\n",
      "Elapsed time: 3.7021484375\n"
     ]
    }
   ],
   "source": [
    "# Classify epoch with varying number of voters\n",
    "print(\"CCA CPU processing\")\n",
    "for (v, voters) in enumerate(n_voters):\n",
    "    temp_times = np.zeros(n_epochs)\n",
    "    temp_accuracy = 0\n",
    "\n",
    "    for e, epoch in enumerate(epochs_subset):\n",
    "        print(f\"- voters: {voters}\")\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Set up classifier and extract features\n",
    "        cca_voters = voters\n",
    "        cca_gpu = False\n",
    "        setup_cca()    \n",
    "        cca_features = np.squeeze(cca.extract_features(epochs[:,e,:,:]))\n",
    "\n",
    "        # Find max correlation across subbands and voters\n",
    "        if (voters == 1):\n",
    "            temp_prediction = np.argmax(np.max(cca_features, axis=0), axis=0)\n",
    "        else:\n",
    "            temp_prediction = np.argmax(np.max(cca_features, axis=(0,1)), axis=0)\n",
    "\n",
    "        end_time = time.time()\n",
    "        temp_times[e] = end_time - start_time\n",
    "        print(f\"Elapsed time: {end_time - start_time}\")\n",
    "\n",
    "        temp_accuracy += 1 if temp_prediction == events_np[epoch] else 0\n",
    "\n",
    "    cca_df.loc[v, \"CPU_time\"] = temp_times.mean()\n",
    "    cca_df.loc[v, \"CPU_accuracy\"] = temp_accuracy / n_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU classification\n",
    "\n",
    "### CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cca_gpu(temp_accuracy):\n",
    "    setup_cca()    \n",
    "    cca_features = np.squeeze(cca.extract_features(epochs[:,e,:,:]))\n",
    "\n",
    "    # Find max correlation across subbands and voters\n",
    "    if (voters == 1):\n",
    "        temp_prediction = np.argmax(np.max(cca_features, axis=0), axis=0)\n",
    "    else:\n",
    "        temp_prediction = np.argmax(np.max(cca_features, axis=(0,1)), axis=0)\n",
    "\n",
    "    predicted_correctly = temp_prediction == events_np[epoch]\n",
    "    \n",
    "    temp_accuracy[0] += 1 if predicted_correctly else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: True, temp accuracy: [1]\n",
      "Predicted: True, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Benchamark run\n",
      "Predicted: True, temp accuracy: [1]\n",
      "Predicted: True, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Benchamark run\n",
      "Predicted: True, temp accuracy: [1]\n",
      "Predicted: True, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Benchamark run\n",
      "Predicted: True, temp accuracy: [1]\n",
      "Predicted: True, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Benchamark run\n",
      "Predicted: True, temp accuracy: [1]\n",
      "Predicted: True, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Predicted: False, temp accuracy: [2]\n",
      "Benchamark run\n"
     ]
    }
   ],
   "source": [
    "cca_gpu_results = []\n",
    "n_warmups = 1\n",
    "\n",
    "for (v, voters) in enumerate(n_voters):\n",
    "    cca_voters = voters\n",
    "    cca_gpu = True\n",
    "    temp_accuracy = [0] # Needs to be a list so it can be modified inside the function\n",
    "    temp_voting_time = np.zeros(len(epochs_subset))\n",
    "\n",
    "    for (e, epoch) in enumerate(epochs_subset):\n",
    "        cca_gpu_results.append(\n",
    "            benchmark(\n",
    "                lambda: time_cca_gpu(temp_accuracy),\n",
    "                n_repeat = 1,\n",
    "                n_warmup = n_warmups,\n",
    "                devices = (0,)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        temp_voting_time[e] = cca_gpu_results[-1].gpu_times[0][0]\n",
    "\n",
    "    cca_df.loc[v, \"GPU_time\"] = np.mean(temp_voting_time)\n",
    "    cca_df.loc[v, \"GPU_accuracy\"] = temp_accuracy[0] / (n_epochs*(1+n_warmups))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssvep-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
