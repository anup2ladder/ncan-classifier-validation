{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOABB Classifier comparison\n",
    "\n",
    "This notebook takes multiple files and does the following pipeline:\n",
    "1) Import data and pre-process\n",
    "2) For each stimulus type \n",
    "    1) Run classifiers (i.e., CCA, MEC, MSI, and RG)\n",
    "    2) Store accuracy values\n",
    "\n",
    "A final plot for each stimulus type is plotted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_types is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.pick_channels_regexp is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "<frozen importlib._bootstrap>:241: FutureWarning: mne.io.pick.channel_type is deprecated will be removed in 1.6, use documented public API instead. If no appropriate public API exists, please open an issue on GitHub.\n",
      "c:\\Users\\danie\\miniconda3\\envs\\ssvep-validation\\Lib\\site-packages\\moabb\\pipelines\\__init__.py:26: ModuleNotFoundError: Tensorflow is not installed. You won't be able to use these MOABB pipelines if you attempt to do so.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use the get_shape_from_baseconcar, InputShapeSetterEEG, BraindecodeDatasetLoaderyou need to install `braindecode`.`pip install braindecode` or Please refer to `https://braindecode.org`.\n"
     ]
    }
   ],
   "source": [
    "# Default libraries\n",
    "import re\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from pyriemann.estimation import Covariances\n",
    "from pyriemann.tangentspace import TangentSpace\n",
    "\n",
    "from moabb.datasets import Wang2016, SSVEPExo\n",
    "from moabb.paradigms import FilterBankSSVEP, SSVEP\n",
    "from moabb.pipelines import ExtendedSSVEPSignal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from moabb.evaluations import CrossSubjectEvaluation\n",
    "\n",
    "\n",
    "# Import custom libraries\n",
    "from functions import data_tools\n",
    "from functions import processing\n",
    "from functions import classification\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorCCA as CCA\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorMSI as MSI\n",
    "from functions.FeatureExtractorSSVEP import FeatureExtractorMEC as MEC\n",
    "\n",
    "# Magic command to reload libraries\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "Note that if the `Wang2016` is not already downloaded, it'll be downloaded the first time you run this section of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n",
      "Trial data de-meaned and concatenated with a buffer to create continuous data\n"
     ]
    }
   ],
   "source": [
    "# Import and epoch data\n",
    "dataset = Wang2016()\n",
    "# dataset = SSVEPExo()\n",
    "dataset.subject_list = dataset.subject_list[:2]\n",
    "data = dataset.get_data()\n",
    "# eeg_channels = [\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "# Information from dataset description\n",
    "nsubjects = len(data)\n",
    "# labels_dict = {\"13\":0, \"17\":2, \"21\":1}  # The order is changed because the labels in the dataset are incorrect\n",
    "# stimulus_freqs = [int(f) for f in labels_dict.keys()]\n",
    "\n",
    "stimulus_freqs = [float(freq) for freq in dataset.event_id.keys()]  # Stimulus frequencies [Hz]\n",
    "srate = data[1][\"0\"][\"0\"].info['sfreq'] # Sampling rate [Hz]\n",
    "tmin = 0.5  # Time of start of SSVEP stimulus [sec]\n",
    "tmax = 5.5  # Time of end of SSVEP stimulus [sec]\n",
    "\n",
    "# Classifier settings\n",
    "# - Create CCA subbands like in Chen et al. (2015) paper\n",
    "first_column = np.arange(1, 11) * 8\n",
    "second_column = np.full(10, 88)\n",
    "cca_subbands = np.column_stack((first_column, second_column))\n",
    "harmonic_count = 2\n",
    "\n",
    "# Create an empty dataframe to store the accuracies\n",
    "accuracy_df = pd.DataFrame(\n",
    "    index = np.arange(0, nsubjects),\n",
    "    columns=['RG_logreg', 'fbCCA', 'MSI', 'MEC'])\n",
    "accuracy_df.index.name = \"Subject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate epochs\n",
    "\n",
    "From the raw recording datasets, create the EEG epochs using just the periods where the SSVEP stimulus was active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate data\n",
    "epochs_list = [None] * len(data)\n",
    "events_list = [None] * len(data)\n",
    "\n",
    "# Obtain epochs and events\n",
    "for s, subject in data.items():\n",
    "    [events_list[s-1], epochs_list[s-1]] = data_tools.moabb_events_to_np(\n",
    "        mne_raw = subject[\"0\"][\"0\"],\n",
    "        tmin = tmin,\n",
    "        tmax = tmax,\n",
    "        events_dict = dataset.event_id,\n",
    "        chans = \"eeg\"\n",
    "        )\n",
    "    \n",
    "# Convert lists to np.ndarrays\n",
    "eeg_channels = data[1][\"0\"][\"0\"].ch_names\n",
    "epochs_np = np.float32(np.array(epochs_list))\n",
    "events_np = np.array(events_list[0][:,2]) - 1   # The `-1` is to make the labels start at 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "### Riemmanian geometry + logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigm_fb = FilterBankSSVEP(\n",
    "    filters = None,\n",
    "    n_classes = 3,\n",
    "    tmin = tmin,\n",
    "    tmax = tmax,\n",
    ")\n",
    "\n",
    "paradigm = SSVEP(\n",
    "    fmin = 6,\n",
    "    fmax = 90,\n",
    "    n_classes = 5,\n",
    "    tmin = tmin,\n",
    "    tmax = tmax,\n",
    ")\n",
    "\n",
    "pipeline_rg = {}\n",
    "pipeline_rg[\"RG+LogReg\"] = make_pipeline(\n",
    "    # ExtendedSSVEPSignal(),\n",
    "    Covariances(estimator=\"lwf\"),\n",
    "    TangentSpace(),\n",
    "    LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\"),\n",
    ")\n",
    "\n",
    "evaluation_rg = CrossSubjectEvaluation(\n",
    "    paradigm = paradigm,\n",
    "    datasets = dataset,\n",
    "    overwrite = False\n",
    ")\n",
    "\n",
    "accuracy_rg = evaluation_rg.process(pipeline_rg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preallocate data\n",
    "rg_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    rg_predictions = classification.fb_rg_logreg(\n",
    "        eeg_data = subject,\n",
    "        stim_freqs = stimulus_freqs,\n",
    "        eeg_channels = eeg_channels, \n",
    "        srate = srate,\n",
    "        labels = events_np,\n",
    "        )\n",
    "    \n",
    "    rg_accuracies[s] = accuracy_score(events_np, rg_predictions)\n",
    "\n",
    "# Store accuracies in dataframe\n",
    "accuracy_df['RG_logreg'] = rg_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rg_accuracies = np.zeros(nsubjects)\n",
    "for [s, subject] in enumerate(epochs_np):\n",
    "    rg_predictions = classification.rg_logreg(\n",
    "        eeg_data = subject,\n",
    "        labels = events_np,\n",
    "        )\n",
    "    \n",
    "    rg_accuracies[s] = accuracy_score(events_np, rg_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04583333, 0.0625    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fbCCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype and preallocate data\n",
    "cca = CCA()\n",
    "cca_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "cca.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1],\n",
    "    filter_order = 12,\n",
    "    subbands = cca_subbands\n",
    "    )\n",
    "    \n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    cca_features = cca.extract_features(subject)\n",
    "    cca_predictions = np.argmax(np.max(np.squeeze(cca_features), axis=1), axis=1)\n",
    "    cca_accuracies[s] = accuracy_score(events_np, cca_predictions)\n",
    "\n",
    "accuracy_df[\"fbCCA\"] = cca_accuracies\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype and preallocate data\n",
    "mec = MEC()\n",
    "mec_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "mec.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    mec_features = mec.extract_features(subject)\n",
    "    mec_predictions = np.argmax(np.squeeze(mec_features), axis=1)\n",
    "    mec_accuracies[s] = accuracy_score(events_np, mec_predictions)\n",
    "\n",
    "accuracy_df[\"MEC\"] = mec_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prototype and preallocate data\n",
    "msi = MSI()\n",
    "msi_accuracies = np.zeros(nsubjects)\n",
    "\n",
    "msi.setup_feature_extractor(\n",
    "    harmonics_count = harmonic_count,\n",
    "    targets_frequencies = stimulus_freqs,\n",
    "    sampling_frequency = srate,\n",
    "    samples_count = epochs_np.shape[-1]\n",
    ")\n",
    "\n",
    "# Classify all epochs per subject\n",
    "for s, subject in enumerate(epochs_np):\n",
    "    msi_features = msi.extract_features(subject)\n",
    "    msi_predictions = np.argmax(np.squeeze(msi_features), axis=1)\n",
    "    msi_accuracies[s] = accuracy_score(events_np, msi_predictions)\n",
    "\n",
    "accuracy_df[\"MSI\"] = msi_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = ['CCA', 'MSI', 'MEC', 'RG_logreg']\n",
    "\n",
    "stimulus_accuracy = accuracy_df[accuracy_df[\"Stimulus\"]==stimulus]\n",
    "\n",
    "fig, ax = plt.subplots(facecolor=\"white\", figsize=[8, 4])\n",
    "sns.stripplot(\n",
    "    data=stimulus_accuracy,\n",
    "    ax=ax,\n",
    "    jitter=True,\n",
    "    alpha=0.5,\n",
    "    zorder=1,\n",
    "    palette=\"Set1\",\n",
    ")\n",
    "sns.pointplot(data=stimulus_accuracy, ax=ax, palette=\"Set1\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.set_title(f\"Stimulus: {stimulus}\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssvep-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
